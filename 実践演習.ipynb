{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNS2zuP7Afpm"
      },
      "source": [
        "# 6章 統計学を学ぼう（分類）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践2-1:\n",
        " y=x^2のある値での傾き(微分)を求める計算式を定義してください。\n",
        "変化点を小さくすることで算出してください。\n"
      ],
      "metadata": {
        "id": "YQ25BqBMQTbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK0AAAA5CAMAAAEEgWuyAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAACWUExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADoLzSoAAAAydFJOUwCdCDa4+WSSK+5ZdKIVhMWyHQrNlIGvUNK/WASGc+JoQl3MN6bngEchYpA8/6uz9OGNBgsemAAAAAlwSFlzAAAXEQAAFxEByibzPwAABHNJREFUWEftmYt2ozYQhmUobWnrFkPr7kK2XXc3NhR1De//cv1HGgECcbNJTrKb7/iYi9AwGs3NiZjmOz4OOHpBJqQUZyH5jpv6yCdj1HxkIj7eybtGcKoPmlgf5Fl4fKYPfaq9eWAR/4qKz8gqG+FQrRShSIQfYwwrydUtKS6466vxLrgTJni6ECmtWj0sxDk3mmKRfFxEJfY1Np2vpjF7mB34hDGKd8nF9eFMJ579cKP4E/M3PMUiY7tbfsO+NLRYInYnswc8R6+y59YAD8AwZ5gQbyglYgc+FgiXvxTiUfsfbxfJtQxS7vlkCauejYRfiitfTbPm2REsIzPKG8CXhE80jZE7FBFvSWzvDBvZwheFt6MQSvoZqRsTXy9HUQ+ThAWsUHRsLns7m7ebZQ1FC/xLbYbMT/gORU07XJ7NXrZyu0MZAmRGX1HpcAhJAOUciWu4CdPIHQ5NgzdjgZgR7kRBF/Ja7EROIggj1zHUgPqBz/ZoudFvovocz1bWFZDQPTlIeRTeXRFtU/n0iVJyrDzgm89O35PHSKHhw5GTTImsv+8nHIuBJ4+ApcNlmjCpZuSuddeFTLnrG0z2j/yRT7cEzcCM838v5Z98SkxsvTXkTecAD/7Z2exC9nJS64XWULYgXiD2AlVCSA9KqhpIlieuHq1Ya2hB/CP9mIBCzKil6qpBNGKtoUjKOcG5spJu7FDkkJEwTVtOBQW1YqA3NIenV6vCNMMUvdROMdM4hibBYnIfS6TiVtPeQX7I7wJGrGNoChX9ew5+tWS5xxl2RmPEOoaYpUl0Jag2WxYcw1PIBFrbLPhwkL+bHwobQDKhMLYeMrdrHF6Z2IA+ZFXyvrne76nYblO7DDKvm4FLRTH3uG4GmddNXfgQHV90XkNNuIqcOpcRhpnXzZFSm/eZr7xzlkzWo4XptcTmd0oQStiktkvT6yO1c6e0yrU9IbCKzd8pHKxMr0sZT69vvPGU1PIk8vC6WbZ+Bup7tPWqANnrYyidacGr5HQWcjIxK4uSqUS9kFK6pGTRr7V7GYbckfzGZ2X1dYsfOVmkxH/axXXgQ3WpknSG9A7bq/LdGzI4tB2fVaqX1M6FrCAPj8ayXvUlMvrUZO/W6t0hg0PbBbPu4VA1ugKyhabQ8VA31myHGobaLpl1O7bf548/hfyakt+SRfqkM9Qy0HbRrJvJQ11/JUwC90IswxYXFOJmACSxNdShr+2yWa8aXTG86p5M/Hy8Fj01Slt4Db5RWAL/43sZfBCHH6T8pRNSLwVt2yxSFtbJpFAZMA+7GeCFYGurckmpanfPRTh6nxd+d8tSbV8Gr0pblaNT/Y0oo56C/hSWxHSLi803wm097yjFnPWyezLZfM+7ijKZ6c9V41Hc+MYFPe8a8r/2utUoUqhV7i5dSQ+40LGHlpbvrWPb7jX7jwynA59zAnlaS6rvetVN2m7cvap/2NF2gT9+7osi22onMH3oOjbuXvV/7EBaozHA5TtlC5vDeyl3t0TZN9C9uhDifysYoQKkQ7eYAAAAAElFTkSuQmCC)\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIYAAAAlCAMAAAHHKFF1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAACNUExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOqHM/gAAAAvdFJOUwCdCDa4+WSS7ll0ohWExbIdCs2Uga9Q0r9YBIZz4kJdN6bngEchYpA8/6uz9OGNf1canwAAAAlwSFlzAAAXEQAAFxEByibzPwAAA0BJREFUSEvtlg13kzAUhtNUFLVKQXEjm6tbBxLX8P9/nu+9N6QphbXraT07xz2nhXze3NyPBDWG9m+i5KdJ8HBcnMQotfHFKbhfWy4LaAliF4pW2aPFf11L+SVstEqW32QxqzoSw2ROzebSnGj05ClKtbWtmnMjVwrbzajYKPtI780JCpwXvbVucucLTLAfRphbCzcA4/dIe1PYmGyfZVgYGuSQQ28agV1SEcBmBhWyhLULMQKNsLF9nqebmxxRs+bfKLA47QVhNjXi32GDVU9HT8mwMHKEOAOYL3EOMJBhIAYuQZdjDzEpidBPwVBBRqHaAq+oa0JGJko8hJlBBvk/g1OjrjNghnvLcrdrh8OUBhGk731Nr02htJxER/OASFysKlfL2rCSyzMu/q+0dhtWJ4OwiqLT41YqrXx5yM5xL+wLEDigt9RBZNbtSRc9sq/K3eddFBpZpX7libI+K4IMU2qEe9zFMrIFzivVlnEO1yzOhWAJMrpcMnrbNSVjKRqh2RNkYEhHCmy7JmQg5In6Y1C3l9FiKl3IURdkzOmH3TeFqimxiRTH9kbZUiV8iYFeBvVYm8ddr4Us2hVhnpa7cXEEFSxwU/qDDldft9genEfSKPKy+y013LI4Rw98Ae0BV8De8K3gTtCjhrM3zY1e8+cI7UUXPrreeMNTpxsEmXb0PIB5/w6Zf/XDV4+ns/0ZNslRCjDacZY3tnjm06AeuVQanGiH1mA1Wh6onU3md9c2uVXLD9Z+Hl+tFTUeU0tZtkp3lRpRo03mfs7krN4aJmN9O752ZL/13lCmxWncl9Z1uvKVnn01uEUEE6OzhmokdO/ISqPeqtMy6GayoBEBi0aEU1pcqR1LBoNZPS9RQ7vYQG06EnlDa5hMFg1uGZ31IjUa2VH9QC+st6uVMFSj64c0bKCJWWiHBSt5IkTJmghsqE5NvSEFamegXmNnkIUx9IoZqBHmgM1ictbrwJt5GjOduOejLbIRP0Ug5cmwYzF1PuqfC3FlU9ERM3sMWQZuUJHARZL6totg/tBWJR18piA9fDwRlbRqd1E1+DvZ5/X3T8MoIWuIP9gzFyPkUtXhEkH1anBMEMtre7HsUuovbyBYUsXtTcMAAAAASUVORK5CYII=)\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAdCAMAAAGLR64jAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAABjUExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGZodN4AAAAhdFJOUwCdCDa4+WTuWRWyHQrNr1DSWARCXTfngEchYjz/s/ThjeMgwr4AAAAJcEhZcwAAFxEAABcRAcom8z8AAADUSURBVChT1ZLRDoIwDEULiFUElInoWGX8/1fabZ3BEV9MNPE8rPd2XVM2YIGVGMhJxBqC2XDQRAaKkHpHeRYBCrLCt6w56yLRnubMqU8hbrUEnc/v1+CgCtsD+vArbA/YiY6YRkSk6uBSl0BxVN261VbeMAfvYY63q0IDvYsHkIgmoBbKm2T+BrXd8PCno9gVufUfOVKTPG+CCQU3JPcT9ZiWG76dqK4aezERje3zgKqetZHcLvsZpORNx9K/jR5c0Ni91rvxhWnPOuM9zYMmI34LgAdDhQsdSS0MwgAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "osWdWVR7Ihox"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdlL1HgpK6Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践2-2(応用)\n",
        "任意の関数を受け取ってその関数の傾き(微分)を求める計算式を関数で定義してください。\n",
        "(関数の引数に関数を渡す: 講義未説明&以前類似を宿題として対応済。必要に応じて調査: 難しい場合は次週の宿題で関連項目を演習としてだします)"
      ],
      "metadata": {
        "id": "SV18y5GhQZxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 傾きを計算する関数を定義\n",
        "def calc_slope(func):\n",
        "    delta: float = 0.00001\n",
        "    result = (func(delta + 3) - func(3)) /((delta + 3) - 3)\n",
        "    return result\n",
        "\n",
        "def test_func(num):\n",
        "    return num ** 2\n",
        "\n",
        "print(calc_slope(test_func))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ssnC30u3Qm",
        "outputId": "a54d029f-e25a-42c9-e8b7-8cf9b196f2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.00000999991201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5i0nnPnAMZ4"
      },
      "source": [
        "# 実践3-1:行列演算\n",
        "以下の演算を実施してください。\n",
        "\n",
        "1. ベクトル同士の足し算・引き算\n",
        "\n",
        "    (a) 足し算:\n",
        "    u = (2, -3, 5),\n",
        "    \n",
        "    v = (-1, 4, 1)\n",
        "    \n",
        "    u + vを計算せよ。\n",
        "\n",
        "    (b) 引き算:\n",
        "\n",
        "    x = (7, -2, 4),\n",
        "    \n",
        "    y = (3, 5, -1)  \n",
        "    \n",
        "    x - yを計算せよ。\n",
        "\n",
        "2. 行列同士の足し算・引き算  \n",
        "\n",
        "    (a) 足し算:\n",
        "    A = \\begin{pmatrix}\n",
        "    1 & 2 & 0\\\\\n",
        "    3 & -1 & 4\\\\\n",
        "    \\end{pmatrix}, B = \\begin{pmatrix}\n",
        "    4 & 1 & 2\\\\\n",
        "    -2 & 3 & 1\\\\  \n",
        "    \\end{pmatrix}\n",
        "    A + Bを計算せよ。\n",
        "\n",
        "    (b) 引き算:  \n",
        "    C = \\begin{pmatrix}\n",
        "    5 & 7 & 2\\\\\n",
        "    -3 & 4 & 6\\\\\n",
        "    1 & -2 & 3\\\\\n",
        "    \\end{pmatrix}, D = \\begin{pmatrix}\n",
        "    2 & -1 & 4\\\\\n",
        "    6 & 3 & -2\\\\\n",
        "    -4 & 1 & 5\\\\\n",
        "    \\end{pmatrix}\n",
        "    C - Dを計算せよ。\n",
        "\n",
        "3. ベクトルのスカラー倍\n",
        "\n",
        "    u = (2, -5, 3)\n",
        "    \n",
        "    2uを計算せよ。\n",
        "\n",
        "4. 行列のスカラー倍  \n",
        "\n",
        "    A = \\begin{pmatrix}\n",
        "    1 & 4 & 2\\\\\n",
        "    3 & -2 & 5\\\\\n",
        "    \\end{pmatrix}\n",
        "    -3Aを計算せよ。  \n",
        "\n",
        "5. 行列同士の掛け算 (3×2)  \n",
        "\n",
        "    A = \\begin{pmatrix}\n",
        "    2 & 1\\\\\n",
        "    3 & 4\\\\\n",
        "    5 & 2\\\\\n",
        "    \\end{pmatrix}, B = \\begin{pmatrix}\n",
        "    6 & 3\\\\\n",
        "    2 & 7\\\\\n",
        "    \\end{pmatrix}\n",
        "    ABを計算せよ。\n",
        "\n",
        "6. 行列とベクトルの掛け算\n",
        "\n",
        "    A = \\begin{pmatrix}\n",
        "    1 & 2 & 3\\\\\n",
        "    4 & 5 & 6\\\\  \n",
        "    \\end{pmatrix}, u = \\begin{pmatrix}\n",
        "    2\\\\\n",
        "    3\\\\\n",
        "    1\\\\\n",
        "    \\end{pmatrix}\n",
        "    Auを計算せよ。\n",
        "\n",
        "7. 行列と単位行列の掛け算\n",
        "\n",
        "    A = \\begin{pmatrix}\n",
        "    2 & 3 & 1\\\\\n",
        "    4 & 0 & 2\\\\\n",
        "    5 & 6 & 7\\\\\n",
        "    \\end{pmatrix}  \n",
        "    AI3を計算せよ。(I3は3×3の単位行列)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.\n",
        "###(a)\n",
        "(1 1 6)\n",
        "###(b)\n",
        "(4 -7 5)\n",
        "\n",
        "\n",
        "##2.\n",
        "###(a)\n",
        "\\begin{pmatrix}\n",
        "    5 & 3 & 2\\\\\n",
        "    1 & 2 & 5\\\\\n",
        "    \\end{pmatrix}\n",
        "\n",
        "###(b)\n",
        "\\begin{pmatrix}\n",
        "    3 & 8 & -2\\\\\n",
        "    -9 & 1 & 8\\\\\n",
        "    5 & -3 & -2\\\\\n",
        "    \\end{pmatrix}\n",
        "\n",
        "##3.\n",
        "###(4 -10 6)\n",
        "\n",
        "##4.\n",
        "\\begin{pmatrix}\n",
        "    -3 & -12 & -6\\\\\n",
        "    -9 & 6 & -15\\\\\n",
        "    \\end{pmatrix}\n",
        "\n",
        "##5.\n",
        "\\begin{pmatrix}\n",
        "    14 & 13\\\\\n",
        "    26 & 37\\\\\n",
        "    34 & 29\\\\\n",
        "    \\end{pmatrix}\n",
        "\n",
        "##6.\n",
        "\\begin{pmatrix}\n",
        "    11\\\\\n",
        "    29\\\\\n",
        "    \\end{pmatrix}\n",
        "\n",
        "##7.\n",
        "\\begin{pmatrix}\n",
        "    2 & 3 & 1\\\\\n",
        "    4 & 0 & 2\\\\\n",
        "    5 & 6 & 7\\\\\n",
        "    \\end{pmatrix}\n"
      ],
      "metadata": {
        "id": "nAFRSLNYL5wY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0m-CKw-Hq4H"
      },
      "source": [
        "# 実践4-1(統計)\n",
        "サンプルデータ\n",
        "生徒10人の数学とプログラミングの試験点数が以下のように与えられています。\n",
        "数学: [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
        "プログラミング: [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
        "\n",
        "問題1: 平均値を求める\n",
        "数学とプログラミングの試験点数それぞれの平均点を求めてください。\n",
        "\n",
        "問題2: 中央値を求める\n",
        "数学とプログラミングの試験点数それぞれの中央値を求めてください。\n",
        "\n",
        "問題3: 最頻値を求める\n",
        "数学とプログラミングの試験点数それぞれの最頻値を求めてください。\n",
        "\n",
        "問題4: 標準偏差と分散を求める\n",
        "数学とプログラミングの試験点数それぞれの標準偏差と分散を求めてください。\n",
        "\n",
        "問題5: 相関係数を求める\n",
        "数学とプログラミングの試験点数の相関係数を求めてください。\n",
        "これらの問題を解くために、平均値、中央値、最頻値、標準偏差、分散、相関係数を計算する関数を作成し、サンプルデータを使って解答の一部を埋めてください。リストの標準ライブラリのみを使用してください。\n",
        "\n",
        "\n",
        "```\n",
        "from math import sqrt\n",
        "\n",
        "# サンプルデータ\n",
        "math_scores = [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
        "prog_scores = [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
        "\n",
        "# 問題1: 平均値\n",
        "def mean(scores):\n",
        "    # ここを埋める\n",
        "\n",
        "math_mean = mean(math_scores)\n",
        "prog_mean = mean(prog_scores)\n",
        "print(f\"数学の平均点: {math_mean}\")\n",
        "print(f\"プログラミングの平均点: {prog_mean}\")\n",
        "\n",
        "# 問題2: 中央値\n",
        "def median(scores):\n",
        "    sorted_scores = sorted(scores)\n",
        "    n = len(sorted_scores)\n",
        "    # 残りの処理を埋める\n",
        "\n",
        "math_median = median(math_scores)\n",
        "prog_median = median(prog_scores)\n",
        "print(f\"数学の中央値: {math_median}\")\n",
        "print(f\"プログラミングの中央値: {prog_median}\")\n",
        "\n",
        "# 問題3: 最頻値\n",
        "def mode(scores):\n",
        "    count = {}\n",
        "    for score in scores:\n",
        "        count[score] = count.get(score, 0) + 1\n",
        "    # 以降を埋める\n",
        "\n",
        "math_mode = mode(math_scores)\n",
        "prog_mode = mode(prog_scores)\n",
        "print(f\"数学の最頻値: {math_mode}\")\n",
        "print(f\"プログラミングの最頻値: {prog_mode}\")\n",
        "\n",
        "# 問題4: 標準偏差と分散\n",
        "def stdev(scores):\n",
        "    mean_val = mean(scores)\n",
        "    # 以降を埋める\n",
        "\n",
        "def variance(scores):\n",
        "    mean_val = mean(scores)\n",
        "    # 以降を埋める\n",
        "\n",
        "\n",
        "math_std = stdev(math_scores)\n",
        "prog_std = stdev(prog_scores)\n",
        "math_var = variance(math_scores)\n",
        "prog_var = variance(prog_scores)\n",
        "print(f\"数学の標準偏差: {math_std}\")\n",
        "print(f\"プログラミングの標準偏差: {prog_std}\")\n",
        "print(f\"数学の分散: {math_var}\")\n",
        "print(f\"プログラミングの分散: {prog_var}\")\n",
        "\n",
        "# 問題5: 相関係数(応用: 数式を確認する必要がある)\n",
        "def covariance(x, y):\n",
        "    x_mean = mean(x)\n",
        "    y_mean = mean(y)\n",
        "    cov = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "    return cov / (len(x) - 1)\n",
        "\n",
        "def corr_coef(x, y):\n",
        "    # 定義する\n",
        "\n",
        "corr = corr_coef(math_scores, prog_scores)\n",
        "print(f\"数学とプログラミングの相関係数: {corr}\")\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import fix_missing_locations\n",
        "from math import sqrt\n",
        "\n",
        "# サンプルデータ\n",
        "math_scores = [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
        "prog_scores = [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
        "\n",
        "# 問題1: 平均値\n",
        "def mean(scores):\n",
        "    # ここを埋める\n",
        "    mean_result = sum(scores)/len(scores)\n",
        "    return mean_result\n",
        "\n",
        "math_mean = mean(math_scores)\n",
        "prog_mean = mean(prog_scores)\n",
        "print(f\"数学の平均点: {math_mean}\")\n",
        "print(f\"プログラミングの平均点: {prog_mean}\")\n",
        "\n",
        "\n",
        "# 問題2: 中央値\n",
        "def median(scores):\n",
        "    sorted_scores = sorted(scores)\n",
        "    n = len(sorted_scores)\n",
        "    # 残りの処理を埋める\n",
        "    if n % 2 == 0:\n",
        "        median_index: int = int(n/2) -1\n",
        "        median_result: float = (sorted_scores[median_index] + sorted_scores[median_index + 1]) / 2\n",
        "    else:\n",
        "        median_index: int = int(n/2 + 0.5) -1\n",
        "        median_result: float = sorted_scores[median_index]\n",
        "\n",
        "    return median_result\n",
        "\n",
        "math_median = median(math_scores)\n",
        "prog_median = median(prog_scores)\n",
        "print(f\"数学の中央値: {math_median}\")\n",
        "print(f\"プログラミングの中央値: {prog_median}\")\n",
        "\n",
        "# 問題3: 最頻値\n",
        "def mode(scores):\n",
        "    count = {}\n",
        "    for score in scores:\n",
        "        count[score] = count.get(score, 0) + 1\n",
        "    # 以降を埋める\n",
        "    mode_result: list[int]  = []\n",
        "    mode_max = max(count.values())\n",
        "    for key,value in count.items():\n",
        "        if value == mode_max:\n",
        "            mode_result.append(key)\n",
        "\n",
        "    return mode_result\n",
        "\n",
        "math_mode = mode(math_scores)\n",
        "prog_mode = mode(prog_scores)\n",
        "print(f\"数学の最頻値: {math_mode}\")\n",
        "print(f\"プログラミングの最頻値: {prog_mode}\")\n",
        "\n",
        "# 問題4: 標準偏差と分散\n",
        "def stdev(scores):\n",
        "    mean_val = mean(scores)\n",
        "    # 以降を埋める\n",
        "    square_divitations: list[float] = []\n",
        "\n",
        "    for value in scores:\n",
        "        divitation: float = value - mean_val\n",
        "        square_divitations.append(divitation**2)\n",
        "\n",
        "    variance_result: float = sum(square_divitations)/len(square_divitations)\n",
        "    stdev_result: float = sqrt(variance_result)\n",
        "    return stdev_result\n",
        "\n",
        "def variance(scores):\n",
        "    mean_val = mean(scores)\n",
        "    # 以降を埋める\n",
        "    square_divitations: list[float] = []\n",
        "\n",
        "    for value in scores:\n",
        "        divitation: float = value - mean_val\n",
        "        square_divitations.append(divitation**2)\n",
        "\n",
        "    variance_result: fix_missing_locations = sum(square_divitations)/len(square_divitations)\n",
        "    return variance_result\n",
        "\n",
        "math_std = stdev(math_scores)\n",
        "prog_std = stdev(prog_scores)\n",
        "math_var = variance(math_scores)\n",
        "prog_var = variance(prog_scores)\n",
        "print(f\"数学の標準偏差: {math_std}\")\n",
        "print(f\"プログラミングの標準偏差: {prog_std}\")\n",
        "print(f\"数学の分散: {math_var}\")\n",
        "print(f\"プログラミングの分散: {prog_var}\")\n",
        "\n",
        "\n",
        "# 問題5: 相関係数(応用: 数式を確認する必要がある)\n",
        "def covariance(x, y):\n",
        "    x_mean = mean(x)\n",
        "    y_mean = mean(y)\n",
        "    cov = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "    return cov / (len(x) - 1)\n",
        "\n",
        "def corr_coef(x, y):\n",
        "    # 定義する\n",
        "    corr_coef_result: float = covariance(x, y)/(stdev(x) * stdev(y))\n",
        "    return corr_coef_result\n",
        "\n",
        "corr = corr_coef(math_scores, prog_scores)\n",
        "print(f\"数学とプログラミングの相関係数: {corr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFHpaKPIaKm",
        "outputId": "86547ebf-7b9d-44d2-84a5-5da444a07faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数学の平均点: 78.6\n",
            "プログラミングの平均点: 79.4\n",
            "数学の中央値: 78.0\n",
            "プログラミングの中央値: 80.0\n",
            "数学の最頻値: [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
            "プログラミングの最頻値: [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
            "数学の標準偏差: 9.971960689854328\n",
            "プログラミングの標準偏差: 8.452218643646175\n",
            "数学の分散: 99.44\n",
            "プログラミングの分散: 71.44\n",
            "数学とプログラミングの相関係数: 0.6665201372516742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践4-2\n",
        "標準正規分布について調べて報告してください。正規分布との違いは何ですか？"
      ],
      "metadata": {
        "id": "44Ki9yGfPFN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準正規分布とは平均を0、標準偏差が1の分布を指し、データがある値以上を取り得る確率を確認する際に使用される。\n",
        "\n",
        "正規分布では、数量や長さといったデータの単位で表現し分布を確認する際に用いられる。\n",
        "\n",
        "これに対して、標準正規分布はデータの分布を確率で表現することにより共通化するといった用途の違いがある。"
      ],
      "metadata": {
        "id": "bgGJqRf9P5D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践4-3(応用):\n",
        "二項分布・ポアソン分布・指数分布・ベルヌーイ分布・幾何分布について調べて報告してください。"
      ],
      "metadata": {
        "id": "Fp-TysV0PRjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###・二項分布\n",
        "結果が成功、失敗の２通りとなる試行を独立して複数回行った場合の成功確率を示した分布\n",
        "\n",
        "縦軸に確率、横軸に成功回数で表現する\n",
        "\n",
        "###・ポアソン分布\n",
        "ある期間に一定確率で発生する事象が、ある期間に何回発生するかを示した確率分布\n",
        "\n",
        "縦軸に確率、横軸に発生回数をとる\n",
        "\n",
        "###・指数分布\n",
        "ある期間に一定確率で発生する事象が、初めて発生するまでの時間を示した確率分布\n",
        "\n",
        "縦軸に確率、横軸に時間をとる\n",
        "\n",
        "\n",
        "###・ベルヌーイ分布\n",
        "結果が成功、失敗の２通りとなる試行を独立して１回行った場合の確率分布\n",
        "\n",
        "縦軸に確率、横軸に失敗と成功をとる。\n",
        "\n",
        "###・幾何分布\n",
        "結果が成功、失敗の２通りとなる試行を独立して行った場合に初めて成功する回数を示した分布\n",
        "\n",
        "縦軸に確率、横軸に何回目で成功したかをとる"
      ],
      "metadata": {
        "id": "UZQk0iU9BEc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-1(回帰)\n",
        "最小二乗法について説明してください。"
      ],
      "metadata": {
        "id": "CWZzXIP0C7FD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最小二乗法とは、予測モデルの予測値と実測値の誤差を２乗し、その和を最小化することで予測モデルをフィットさせる手法である。\n",
        "\n",
        "ただし、誤差を２乗するため外れ値による影響を受けやすいという特徴がある。"
      ],
      "metadata": {
        "id": "kr12cS0z7OOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-2:\n",
        "過学習について説明してください。\n",
        "過学習が起きると何が問題でしょうか。"
      ],
      "metadata": {
        "id": "gZyPq3q-C8gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "過学習とは、既知データに対して過度に合致するモデルを構築するである。\n",
        "これにより予測が、実際のデータとかけ離れてしまうことが問題として挙げられる。\n",
        "原因としては、学習データの不足や過度なモデル複雑化があげられる。\n",
        "対策としては、手元のデータを学習データとテストデータに分けることで、\n",
        "学習をしていないテストデータに対して精度が出ているかをテストするといった方法が使用される。"
      ],
      "metadata": {
        "id": "niJ2sjrW6-0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-3:\n",
        "決定係数R^2 を使う場面について説明してください。"
      ],
      "metadata": {
        "id": "_N3YsSuBXAbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定係数とは、発生した誤差の内、モデルによる説明可能な誤差がどれくらいあったかを図るための指標である。\n",
        "具体的な使用場面としては、複数モデル間の比較やモデルの精度を評価する際に用いられる。特に変数の数が異なるモデルを比較する際には、変数の数を考慮に入れた自由度修正済み決定係数が用いられる。"
      ],
      "metadata": {
        "id": "1PgL2LK26D73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-4:\n",
        "以下の決定係数の算出問題を計算してください。\n",
        "\n",
        "データセット\n",
        "\n",
        "x (年収/万円): 300, 400, 500, 600, 700\n",
        "\n",
        "y (支出額/万円): 150, 220, 300, 380, 420\n",
        "\n",
        "以下のサンプルコードを埋めてください。\n",
        "\n",
        "\n",
        "```\n",
        "import math\n",
        "\n",
        "# データ\n",
        "x = [300, 400, 500, 600, 700]\n",
        "y = [150, 220, 300, 380, 420]\n",
        "n = len(x)\n",
        "\n",
        "# 平均値\n",
        "x_mean = sum(x) / n\n",
        "y_mean = sum(y) / n\n",
        "\n",
        "# 直線の係数 a, b (最小二乗法)\n",
        "numer = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "denom = sum((x_i - x_mean) ** 2 for x_i in x)\n",
        "a = numer / denom\n",
        "b = y_mean - a * x_mean\n",
        "\n",
        "# 予測値\n",
        "y_pred = [a * x_i + b for x_i in x]\n",
        "\n",
        "# 決定係数\n",
        "ss_res = #ここを埋める\n",
        "ss_tot = #ここを埋める\n",
        "r_squared = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(f\"直線の係数: a = {a}, b = {b}\")\n",
        "print(f\"決定係数 R^2 = {r_squared}\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "ItWN1B9eXKlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# データ\n",
        "x = [300, 400, 500, 600, 700]\n",
        "y = [150, 220, 300, 380, 420]\n",
        "n = len(x)\n",
        "\n",
        "# 平均値\n",
        "x_mean = sum(x) / n\n",
        "y_mean = sum(y) / n\n",
        "\n",
        "# 直線の係数 a, b (最小二乗法)\n",
        "numer = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "denom = sum((x_i - x_mean) ** 2 for x_i in x)\n",
        "a = numer / denom\n",
        "b = y_mean - a * x_mean\n",
        "\n",
        "# 予測値\n",
        "y_pred = [a * x_i + b for x_i in x]\n",
        "\n",
        "# 決定係数\n",
        "ss_res = sum((y_i - y_pred_i) ** 2 for y_i,y_pred_i in zip(y, y_pred))#ここを埋める\n",
        "ss_tot = sum((y_i - y_mean) ** 2 for y_i in y)#ここを埋める\n",
        "r_squared = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(f\"直線の係数: a = {a}, b = {b}\")\n",
        "print(f\"決定係数 R^2 = {r_squared}\")\n",
        "# print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeRWBSyE9ocU",
        "outputId": "b73daf84-f087-4564-a2bd-d1671e510f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "直線の係数: a = 0.7, b = -56.0\n",
            "決定係数 R^2 = 0.9894991922455574\n",
            "[154.0, 224.0, 294.0, 364.0, 433.99999999999994]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-5\n",
        "単回帰と重回帰の違いを数式を例にして説明してください。"
      ],
      "metadata": {
        "id": "mPOji6izU0MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "単回帰と重回帰の違いとしては、下記の通り説明変数が一つか複数個あるかという点が挙げられる。\n",
        "\n",
        "単回帰: y = β0 + β1x\n",
        "\n",
        "重回帰: y = β0 + β1x1 + β2x2 + β3x3 ....\n",
        "\n",
        "家賃予測(y)の場合を考えると、単回帰は部屋広さ(x1)という一つの説明変数で予測を行う。対して重回帰では、部屋の広さ(x1)、駅からの距離(x2)、築年数(x3)など複数の説明変数による予測を行う。\n",
        "\n",
        "複数の変数を用いるため、重回帰の方が精度の高い分析を行うことができる。しかし、関連が強い変数を用いると、変数同士が影響しあうことにより、どの変数が重要かの判断が難しくなる。\n"
      ],
      "metadata": {
        "id": "D1K9chkcB6jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践5-6\n",
        "リッジ回帰・ラッソ回帰・elastic-netの違いについて調べて報告してください。例えば説明変数の数が多い場合はどの手法を使うべきでしょうか？"
      ],
      "metadata": {
        "id": "QGG0UZrGU3cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "リッジ回帰: 最小二乗法によって誤差を小さくする際に、ペナルティとして全ての説明変数の傾きの2乗和(L2ノルム)を加える。回帰式を求める際には、影響度の少ない説明変数の傾きを選択的に小さくする。\n",
        "\n",
        "ラッソ回帰: 最小二乗法によって誤差を小さくする際に、ペナルティとして全ての説明変数の傾きの絶対値の合計(L1ノルム)を加える。回帰式を求める際には、影響度の少ない説明変数の傾きが0になることがあり、説明変数を取捨選択する際に用いられる。\n",
        "\n",
        "elastic-net: リッジ回帰とラッソ回帰の複合であり、ペナルティとしてL1ノルムとL2ノルムを加え、傾きを求めていく。リッジ回帰、ラッソ回帰と同様にペナルティの強さであるλをハイパーパラメータとして持つほか、L1正則化の割合も指定する必要がある。\n",
        "\n",
        "説明変数の多い場合には、使い分けを行う必要がある。全ての説明変数が重要と考えられる場合には、リッジ回帰を使用する。説明変数の中に不要なものがあると考えられる場合には、ラッソ回帰または、elastic-netを使用する。"
      ],
      "metadata": {
        "id": "HkUCqIeTKFbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践6-1(分類: 混同行列/評価指標の定義)\n",
        "以下の実際のラベル値と予測値が与えられています。混同行列、Recall、Precision、F値をそれぞれ計算してください。ライブラリは使わず手計算で行ってその結果を記載してください。\n",
        "\n",
        "補足) Recall=再現率, Precision=適合率\n",
        "\n",
        "実際のラベル値: [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
        "\n",
        "予測値: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]"
      ],
      "metadata": {
        "id": "7ssYaOlVKoNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_data: list[int] = [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
        "predict_data: list[int] = [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
        "\n",
        "# 混同行列を定義\n",
        "pp: int = 0 # 実測 = 1, 予測 = 1\n",
        "pn: int = 0 # 実測 = 1, 予測 = 0\n",
        "np: int = 0 # 実測 = 0, 予測 = 1\n",
        "nn: int = 0 # 実測 = 0, 予測 = 0\n",
        "\n",
        "for true, predict in zip(true_data, predict_data):\n",
        "    if true == 1:\n",
        "        if true == predict:\n",
        "            pp = pp + 1\n",
        "        else:\n",
        "            pn = pn + 1\n",
        "    elif true == 0:\n",
        "        if true == predict:\n",
        "            nn = nn + 1\n",
        "        else:\n",
        "            np = np + 1\n",
        "\n",
        "# 混同行列を定義\n",
        "confusion_matrix: list[list[int], list[int]] = [[pp, pn], [np, nn]]\n",
        "\n",
        "# 各指標を計算\n",
        "recall: float = confusion_matrix[1][1] / sum(confusion_matrix[1])\n",
        "precision: float = confusion_matrix[1][1] / (confusion_matrix[0][1] + confusion_matrix[1][1])\n",
        "f_value = (2 * recall * precision) / (recall + precision)\n",
        "\n",
        "print(confusion_matrix)\n",
        "print(recall)\n",
        "print(precision)\n",
        "print(f_value)\n"
      ],
      "metadata": {
        "id": "PUI_qEiZV1AW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05742c06-d3b7-424b-824b-172f7c9fc1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 2], [2, 3]]\n",
            "0.6\n",
            "0.6\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践6-2 (応用)\n",
        "* 不純度はGini不純度とエントロピーが代表的です。\n",
        "* エントロピーについて概要を調べてみてください。"
      ],
      "metadata": {
        "id": "ImY-zg34KrMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "エントロピーとはデータの不確実性や情報量を測定する指標である。\n",
        "確率が低い事象が発生する場合に情報量が大きくなるため、分布が均等ではないほど数値上は大きくなる。\n",
        "不確実性が高い分布に対して、より過敏に反応するが、一方でGini不純度と比べて計算が複雑な点が特徴として挙げられる。\n",
        "このような不純度の指標を下げる条件分岐を選択し、学習を行う。"
      ],
      "metadata": {
        "id": "fftLVQHfPM5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践6-3\n",
        "* 木構造で過学習を防ぐ方法としてどんな方法がありますか？"
      ],
      "metadata": {
        "id": "H6CJGH5PKytp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・木構造の深さに上限を設ける : 既知のデータに対して過剰に適合することを防ぐ\n",
        "\n",
        "・木構造の葉（条件分岐の最も先の部分）の数に上限を設ける : 過剰な場合分けを防ぐ\n",
        "\n",
        "・葉のデータ数に最小値を設ける : まれに発生する事象に対して学習をすることを防ぐ\n",
        "\n"
      ],
      "metadata": {
        "id": "efOnUga36GrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践6-4(応用)\n",
        "* https://terakoya.sejuku.net/programs/104/chapters/1319#6.4-%E5%88%86%E9%A1%9E%E3%81%AE%E6%B5%81%E3%82%8C\n",
        "* 上記説明でのGini不純度の計算過程をPythonを用いて計算してみてください。条件分岐なしから「勉強時間」「体調」によるそれぞれの不純度の算出とどちらの条件が良いかの判定まで。\n",
        "\n",
        " Gini不純度は以下の関数を利用して計算ください。"
      ],
      "metadata": {
        "id": "MV4OinSHPfTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_impurity(pass_count: int, fail_count: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the Gini impurity for a binary classification problem.\n",
        "\n",
        "    Args:\n",
        "        pass_count (int): The number of passing instances.\n",
        "        fail_count (int): The number of failing instances.\n",
        "\n",
        "    Returns:\n",
        "        float: The Gini impurity value.\n",
        "    \"\"\"\n",
        "    total_count = pass_count + fail_count\n",
        "    if total_count == 0:\n",
        "        return 0\n",
        "    p_pass = pass_count / total_count\n",
        "    p_fail = fail_count / total_count\n",
        "    return 1 - (p_pass ** 2 + p_fail ** 2)"
      ],
      "metadata": {
        "id": "OpOsHHPRPf2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_impurity(pass_count: int, fail_count: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the Gini impurity for a binary classification problem.\n",
        "\n",
        "    Args:\n",
        "        pass_count (int): The number of passing instances.\n",
        "        fail_count (int): The number of failing instances.\n",
        "\n",
        "    Returns:\n",
        "        float: The Gini impurity value.\n",
        "    \"\"\"\n",
        "    total_count = pass_count + fail_count\n",
        "    if total_count == 0:\n",
        "        return 0\n",
        "    p_pass = pass_count / total_count\n",
        "    p_fail = fail_count / total_count\n",
        "    return 1 - (p_pass ** 2 + p_fail ** 2)\n",
        "\n",
        "# テキストデータを変換する関数を定義\n",
        "def create_dummy(input_list: list[str], positive) -> list[int]:\n",
        "    dummy_list: list[int] = []\n",
        "    for item in input_list:\n",
        "        if item == positive:\n",
        "            dummy_list.append(1)\n",
        "        else:\n",
        "            dummy_list.append(0)\n",
        "    return dummy_list\n",
        "\n",
        "# 加重平均後のgini不純度を出力する関数を定義\n",
        "def gini_calculate(branch_list, results_list) -> float:\n",
        "\n",
        "    positive_pass_count: int = 0\n",
        "    positive_fail_count: int = 0\n",
        "    negative_pass_count: int = 0\n",
        "    negative_fail_count: int = 0\n",
        "\n",
        "    for branch, result in zip(branch_list, results_list):\n",
        "        if branch == 1:\n",
        "            if result == 1:\n",
        "                positive_pass_count = positive_pass_count + 1\n",
        "            else:\n",
        "                positive_fail_count = positive_fail_count + 1\n",
        "        else:\n",
        "            if result == 1:\n",
        "                negative_pass_count = negative_pass_count + 1\n",
        "            else:\n",
        "                negative_fail_count = negative_fail_count + 1\n",
        "\n",
        "    total_positive = positive_pass_count + positive_fail_count\n",
        "    total_negative = negative_pass_count + negative_fail_count\n",
        "    total_data = total_positive + total_negative\n",
        "\n",
        "    positive_gini = gini_impurity(positive_pass_count, positive_fail_count)\n",
        "    negative_gini = gini_impurity(negative_pass_count, negative_fail_count)\n",
        "    total_gini = positive_gini * (total_positive / total_data) + negative_gini * (total_negative / total_data)\n",
        "\n",
        "    return total_gini\n",
        "\n",
        "study_times: list[int] = [5, 20, 15, 15, 20, 15, 15, 5, 5]\n",
        "conditions: list[str] = [\"悪い\", \"良い\", \"悪い\", \"良い\", \"悪い\", \"良い\", \"悪い\", \"良い\", \"悪い\"]\n",
        "results: list[str] = [\"不合格\", \"合格\", \"不合格\", \"合格\", \"合格\", \"合格\", \"不合格\", \"不合格\", \"不合格\"]\n",
        "\n",
        "# テキストデータを変換する\n",
        "conditions_dummy: list[int] = create_dummy(conditions, \"良い\")\n",
        "results_dummy: list[int] = create_dummy(results, \"合格\")\n",
        "\n",
        "# 学習時間が10時間以上を1に、それ以外を0に変換する\n",
        "study_time_replace: list[int] = []\n",
        "for study_time in study_times:\n",
        "    if study_time >= 10:\n",
        "        study_time_replace.append(1)\n",
        "    else:\n",
        "        study_time_replace.append(0)\n",
        "\n",
        "\n",
        "# 初期時点でのgini不純度を計算する\n",
        "pass_count: int = 0\n",
        "fail_count: int = 0\n",
        "\n",
        "for result in results_dummy:\n",
        "    if result == 1:\n",
        "        pass_count = pass_count + 1\n",
        "    else:\n",
        "        fail_count = fail_count + 1\n",
        "\n",
        "initial_gini = gini_impurity(pass_count,fail_count)\n",
        "\n",
        "# 分岐後のgini不純度を計算し出力する\n",
        "study_time_gini = gini_calculate(study_time_replace, results_dummy)\n",
        "condition_gini = gini_calculate(conditions_dummy, results_dummy)\n",
        "\n",
        "print(f\"初期状態では{initial_gini}\")\n",
        "print(f\"学習時間で分岐後では{study_time_gini}\")\n",
        "print(f\"体調で分岐後では{condition_gini}\")\n",
        "\n",
        "if study_time_gini > condition_gini:\n",
        "    print(f\"体調を分岐条件とすることが望ましいです。\")\n",
        "elif study_time_gini < condition_gini:\n",
        "    print(f\"学習時間を分岐条件とすることが望ましいです。\")\n",
        "else:\n",
        "    print(f\"どちらの指標にも優位性はありません。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwSgBik0fdL1",
        "outputId": "09a79047-f7ab-4483-c94f-c7c5d5270016"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態では0.49382716049382713\n",
            "学習時間で分岐後では0.2962962962962963\n",
            "体調で分岐後では0.34444444444444433\n",
            "学習時間を分岐条件とすることが望ましいです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実践7-1(クラスタリング): 応用\n",
        "* 調査問題1: クラスタリングアルゴリズムの種類と特徴\n",
        "    * クラスタリングにはどのようなアルゴリズムがあるか調べてみましょう。代表的なアルゴリズムの種類、概要、利点・欠点をまとめてください。\n",
        "\n",
        "* 調査問題2: 距離尺度の種類と使い分け\n",
        "    * クラスタリングでは、データ点間の類似性を測る尺度が必要です。様々な距離尺度があるので、代表的な距離尺度とその特徴、使い分けをまとめてください。\n",
        "\n",
        "* 調査問題3: 質的データのクラスタリング\n",
        "    * これまでは数値データを扱いましたが、質的データ(カテゴリデータ)をクラスタリングする方法も考えられます。質的データをクラスタリングする際の工夫点や注意点を調べてみましょう。\n",
        "\n",
        "* 調査問題4: クラスタリング評価指標\n",
        "    * クラスタリング結果の良し悪しを評価する指標があります。代表的な評価指標とその概要、利用シーンをまとめてください。ヒント: 著名な評価指標としてエルボー法がありますのでエルボー法についてまずは調べ、それ以外にあるか調査してみてください。\n",
        "\n",
        "* 調査問題5: クラスタリングの実践的な利用例\n",
        "    * クラスタリングはどのような分野で利用されているか、実践的な利用例を調べてみましょう。マーケティング、画像処理、自然言語処理などの具体例を挙げてください。"
      ],
      "metadata": {
        "id": "fQXUw5RMP310"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 調査問題1: クラスタリングアルゴリズムの種類と特徴\n",
        "    * 非階層的クラスタリング : 階層を作成せずに行うクラスタリングの手法\n",
        "      * k-means\n",
        "        * クラスタ内の距離の総和を最小化する方法\n",
        "        * 計算速度が速いというメリットがある\n",
        "        * 初期値に左右され、場合によっては正しくない解を導き出す場合がある。\n",
        "    * 階層的クラスタリング\n",
        "      * ウォード法\n",
        "        * 分散が最小になるようにデータをクラスタリングする方法\n",
        "        * 分類の感度が高い点がメリット\n",
        "        * 計算量が多くなることがデメリット\n",
        "      * 最短距離法\n",
        "        * 要素同士の距離を計算し、最短のものをクラスタ間の距離として考える方法\n",
        "        * ウォード法と比べて計算量が少なくなる\n",
        "        * 外れ値に弱い点がデメリット\n",
        "      * 最長距離法\n",
        "        * 要素同士の距離を計算し、最長のものをクラスタ間の距離として考える方法\n",
        "        * ウォード法と比べて計算量が少なくなる\n",
        "        * 外れ値に弱い点がデメリット\n",
        "      * 群平均法\n",
        "        * 全てのデータ間の距離を求めた上で、その平均値をクラスタ間の距離とする方法\n",
        "        * 外れ値に強いというメリットを持つ\n",
        "* 調査問題2: 距離尺度の種類と使い分け\n",
        "    * ユークリッド距離\n",
        "        * 2点間の直線距離\n",
        "    * マンハッタン距離\n",
        "        * 各次元における距離を計算し、その和をとったもの\n",
        "        * 次元数が多い場合に使用される\n",
        "    * ミンコフスキー距離\n",
        "        * ユークリッド距離とマンハッタン距離を含む指標\n",
        "    * マハラノビス距離\n",
        "        * サンプル間の相関関係を考慮した距離計算方法\n",
        "        * 変数同士に相関がある場合に用いられる\n",
        "    * チェビシェフ距離\n",
        "        * 各次元における差の絶対値を算出し、その中から最大となるもの\n",
        "\n",
        "* 調査問題3: 質的データのクラスタリング\n",
        "    * カテゴリーデータをダミー変数(0か1などの数値)に変換してクラスタリングを行う。注意点としては、学習データにない質的データは予測できないという点挙げられる。\n",
        "\n",
        "* 調査問題4: クラスタリング評価指標\n",
        "    * エルボー法\n",
        "        * 誤差平方和を計算し、クラスター数を変えた時の変化を図示する。誤差平方和の減少が少なくなった点が最適なクラスタ数と判断する。\n",
        "        * 初期のクラスタ数を決定する際に使用される。\n",
        "    * シルエット法\n",
        "        * クラスタ内の凝集度とクラスタ間の乖離度を用いてシルエット係数を算出し、クラスタの妥当性を判断する。\n",
        "        * 実行されたクラスタリングについて妥当性があるかを判断する際に使用される。\n",
        "    * Calinski-Harabasz\n",
        "        * クラスタ間の分散とクラスタ内の分散の比率を用いて、クラスタリングの品質を評価する。\n",
        "        * 異なるクラスタリング手法やパラメータ設定の比較にをする際に使用される。\n",
        "    * Davies-Bouldin\n",
        "        * クラスタ内の距離とクラスタ外の距離の比率を用いて、クラスタリングの品質を評価する\n",
        "\n",
        "* 調査問題5: クラスタリングの実践的な利用例\n",
        "    * マーケティングにおける顧客分類\n",
        "    * クレジットカード使用の異常検知\n",
        "    * 自動運転における車両や歩行者の識別\n",
        "    * 商品のレコメンド機能\n",
        "    * 画像処理による軽量化\n",
        "    * CT画像の解析\n",
        "    * テキストマイニングによる感情分析\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "G_WeuJ3N9x7T"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}